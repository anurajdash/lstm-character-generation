{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Character-Character Model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Imc3EikAIGfL"
      },
      "source": [
        "### Load libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ID54J7ZGmR9O",
        "colab_type": "code",
        "outputId": "6b1f8b63-4baa-4c5b-ca0a-e41d8a093ea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-14T23:57:20.051203Z",
          "start_time": "2019-05-14T23:57:19.626384Z"
        },
        "colab_type": "code",
        "id": "49ZVf6F208qa",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import string\n",
        "import unicodedata\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lJeIx1vjIGfQ"
      },
      "source": [
        "### Device selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kk8MIG2wIGfR",
        "outputId": "79ee29a6-a603-4893-d181-6fab530092e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iUI4Mnxm08qk"
      },
      "source": [
        "### Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-14T23:57:20.060842Z",
          "start_time": "2019-05-14T23:57:20.053165Z"
        },
        "colab_type": "code",
        "id": "l8jIBoFd08qm",
        "outputId": "6a26ca8a-3fa0-45d7-d689-06047b52428d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "all_chars = string.ascii_letters + \" .,;'-\\n\"\n",
        "num_chars = len(all_chars)\n",
        "\n",
        "# From https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
        "def unicode_to_ascii(string):\n",
        "  return ''.join([\n",
        "      char for char in unicodedata.normalize('NFD', string) \n",
        "      if char in all_chars])\n",
        "\n",
        "file            = unicode_to_ascii(open('/content/gdrive/My Drive/Data/input.txt', \n",
        "                                        encoding='utf-8').read())\n",
        "file_len        = len(file)\n",
        "print('Length of file: {}'.format(file_len))\n",
        "print('All possible characters: {}'.format(all_chars))\n",
        "print('Number of all possible characters: {}'.format(num_chars))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of file: 1100413\n",
            "All possible characters: abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .,;'-\n",
            "\n",
            "Number of all possible characters: 59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-14T23:57:20.077596Z",
          "start_time": "2019-05-14T23:57:20.064808Z"
        },
        "colab_type": "code",
        "id": "8UBnXaZ308qx",
        "colab": {}
      },
      "source": [
        "# Get a sample sequence of the Shakespeare dataset.\n",
        "def sample_sequence():\n",
        "    sequence_length = 128\n",
        "    index_start = np.random.randint(file_len - sequence_length - 1)\n",
        "    index_end = index_start + sequence_length + 1\n",
        "    input_sequence = file[index_start:index_end]\n",
        "    return input_sequence\n",
        "\n",
        "# Convert the sequence to one-hot tensor.\n",
        "def sequence_to_onehot(seq):\n",
        "    tensor = torch.zeros(len(seq), 1, num_chars) \n",
        "    for t, char in enumerate(seq):\n",
        "        index = all_chars.index(char)\n",
        "        tensor[t][0][index] = 1\n",
        "    return tensor\n",
        "\n",
        "# Convert the sequence to target tensor.\n",
        "def sequence_to_target(seq):\n",
        "    tensor = torch.zeros(len(seq), 1)\n",
        "    for t, char in enumerate(seq):\n",
        "        tensor[t] = all_chars.index(char)\n",
        "    return tensor\n",
        "\n",
        "# Sample a mini-batch including input tensor and target tensor.\n",
        "def get_input_and_target():\n",
        "    seq    = sample_sequence()\n",
        "    input  = sequence_to_onehot(seq[:-1])      \n",
        "    target = sequence_to_target(seq[1:]).long() \n",
        "    return input, target\n",
        "\n",
        "# From https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
        "# Time elapsed for each epoch and its respective iterations\n",
        "def timeSince(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = (s//60)\n",
        "    s -= m*60\n",
        "    return '{} minute(s) {} second(s)'.format(int(m), int(s))\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "atw8EXD408q9"
      },
      "source": [
        "### LSTM Network Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-14T23:57:22.437344Z",
          "start_time": "2019-05-14T23:57:20.131573Z"
        },
        "colab_type": "code",
        "id": "L785__sc08q_",
        "colab": {}
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.input_size  = input_size  \n",
        "        self.hidden_size = hidden_size       \n",
        "        self.output_size = output_size \n",
        "        self.loss_history = []\n",
        "        self.print_iterations = 500\n",
        "        \n",
        "        self.LSTM = nn.LSTM(self.input_size, self.hidden_size, num_layers = 1)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
        "         \n",
        "    def forward(self, input, hidden):\n",
        "        output, hidden = self.LSTM(input.view(1, 1, -1), hidden)\n",
        "        output = self.dropout(output)\n",
        "        output = self.fc(output.view(1, -1))\n",
        "        output= F.log_softmax(output, dim = -1)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.zeros(1, 1,self.hidden_size).to(device), \n",
        "                torch.zeros(1, 1,self.hidden_size).to(device))\n",
        "      \n",
        "    def train(self, optimizer, criterion, epochs, iterations):\n",
        "        initial_time = time.time()\n",
        "        for i in range(epochs):\n",
        "            total_loss = 0\n",
        "            for j in range(iterations):\n",
        "              \n",
        "                input, target = get_input_and_target()\n",
        "                input  = input.to(device)\n",
        "                target = target.to(device)\n",
        "                \n",
        "                sequence_length = input.shape[0]\n",
        "                hidden = self.init_hidden()\n",
        "                self.zero_grad()\n",
        "                loss = 0\n",
        "              \n",
        "                for k in range(sequence_length):    \n",
        "                    output, hidden = self(input[k], hidden)\n",
        "                    loss += criterion(output, target[k])\n",
        "\n",
        "                loss.backward()             \n",
        "                optimizer.step()\n",
        "              \n",
        "                loss_per_iter = loss / sequence_length   \n",
        "                total_loss += loss_per_iter.item()                                \n",
        "   \n",
        "                if j % self.print_iterations == self.print_iterations - 1:\n",
        "                    print('Epoch: {} | Iteration: {}/{}'\n",
        "                    .format(i+1, j, iterations))\n",
        "                    print('Loss: {}\\nTime: {}\\n'\n",
        "                          .format(total_loss/self.print_iterations, timeSince(initial_time)))\n",
        "        \n",
        "                    self.loss_history.append(total_loss/self.print_iterations)\n",
        "                    total_loss = 0  \n",
        "    \n",
        "    def generate(self, initial_sequence='W', predicted_length=100):\n",
        "        hidden        = self.init_hidden()\n",
        "        initial_input = sequence_to_onehot(initial_sequence).to(device)\n",
        "        predicted_sequence = initial_sequence\n",
        "\n",
        "        for i in range(len(initial_sequence) - 1):\n",
        "            output, hidden = net(initial_input[i], hidden)\n",
        "        \n",
        "        input = initial_input[-1]\n",
        "    \n",
        "        for i in range(predicted_length):\n",
        "            output, hidden = self(input, hidden)    \n",
        "            predicted_index = torch.multinomial(output.view(-1).exp(), 1)[0]\n",
        "            predicted_char  = all_chars[predicted_index]\n",
        "            predicted_sequence  += predicted_char\n",
        "            input = sequence_to_onehot(predicted_char)[0].to(device)\n",
        "\n",
        "        return predicted_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lDCAtFOJ08rK"
      },
      "source": [
        "### Training Procedure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HbWQJ-RYsy82",
        "outputId": "ba65d8bf-e377-40d0-ad45-0ff402cde67e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sq = LSTM(num_chars, 512, num_chars)\n",
        "model = sq.cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "epochs = 60\n",
        "iterations = 1000\n",
        "model.train(optimizer, criterion, epochs, iterations)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | Iteration: 499/1000\n",
            "Loss: 2.5982744443416594\n",
            "Time: 1 minute(s) 23 second(s)\n",
            "\n",
            "Epoch: 1 | Iteration: 999/1000\n",
            "Loss: 2.1254737606048586\n",
            "Time: 2 minute(s) 46 second(s)\n",
            "\n",
            "Epoch: 2 | Iteration: 499/1000\n",
            "Loss: 1.9694573953151704\n",
            "Time: 4 minute(s) 8 second(s)\n",
            "\n",
            "Epoch: 2 | Iteration: 999/1000\n",
            "Loss: 1.8854235243797302\n",
            "Time: 5 minute(s) 29 second(s)\n",
            "\n",
            "Epoch: 3 | Iteration: 499/1000\n",
            "Loss: 1.8137236771583558\n",
            "Time: 6 minute(s) 51 second(s)\n",
            "\n",
            "Epoch: 3 | Iteration: 999/1000\n",
            "Loss: 1.7612533905506134\n",
            "Time: 8 minute(s) 12 second(s)\n",
            "\n",
            "Epoch: 4 | Iteration: 499/1000\n",
            "Loss: 1.730601868391037\n",
            "Time: 9 minute(s) 35 second(s)\n",
            "\n",
            "Epoch: 4 | Iteration: 999/1000\n",
            "Loss: 1.7209507598876954\n",
            "Time: 10 minute(s) 58 second(s)\n",
            "\n",
            "Epoch: 5 | Iteration: 499/1000\n",
            "Loss: 1.68990131855011\n",
            "Time: 12 minute(s) 21 second(s)\n",
            "\n",
            "Epoch: 5 | Iteration: 999/1000\n",
            "Loss: 1.6579795668125152\n",
            "Time: 13 minute(s) 44 second(s)\n",
            "\n",
            "Epoch: 6 | Iteration: 499/1000\n",
            "Loss: 1.643917755126953\n",
            "Time: 15 minute(s) 6 second(s)\n",
            "\n",
            "Epoch: 6 | Iteration: 999/1000\n",
            "Loss: 1.6165669260025024\n",
            "Time: 16 minute(s) 28 second(s)\n",
            "\n",
            "Epoch: 7 | Iteration: 499/1000\n",
            "Loss: 1.6028613471984863\n",
            "Time: 17 minute(s) 50 second(s)\n",
            "\n",
            "Epoch: 7 | Iteration: 999/1000\n",
            "Loss: 1.6039895598888396\n",
            "Time: 19 minute(s) 11 second(s)\n",
            "\n",
            "Epoch: 8 | Iteration: 499/1000\n",
            "Loss: 1.5949309568405152\n",
            "Time: 20 minute(s) 33 second(s)\n",
            "\n",
            "Epoch: 8 | Iteration: 999/1000\n",
            "Loss: 1.5844873704910278\n",
            "Time: 21 minute(s) 56 second(s)\n",
            "\n",
            "Epoch: 9 | Iteration: 499/1000\n",
            "Loss: 1.57446288561821\n",
            "Time: 23 minute(s) 21 second(s)\n",
            "\n",
            "Epoch: 9 | Iteration: 999/1000\n",
            "Loss: 1.5661840744018554\n",
            "Time: 24 minute(s) 43 second(s)\n",
            "\n",
            "Epoch: 10 | Iteration: 499/1000\n",
            "Loss: 1.5648853294849396\n",
            "Time: 26 minute(s) 6 second(s)\n",
            "\n",
            "Epoch: 10 | Iteration: 999/1000\n",
            "Loss: 1.5522619388103485\n",
            "Time: 27 minute(s) 29 second(s)\n",
            "\n",
            "Epoch: 11 | Iteration: 499/1000\n",
            "Loss: 1.5641902596950532\n",
            "Time: 28 minute(s) 51 second(s)\n",
            "\n",
            "Epoch: 11 | Iteration: 999/1000\n",
            "Loss: 1.5339615526199342\n",
            "Time: 30 minute(s) 14 second(s)\n",
            "\n",
            "Epoch: 12 | Iteration: 499/1000\n",
            "Loss: 1.5300960578918457\n",
            "Time: 31 minute(s) 37 second(s)\n",
            "\n",
            "Epoch: 12 | Iteration: 999/1000\n",
            "Loss: 1.5313742940425872\n",
            "Time: 33 minute(s) 0 second(s)\n",
            "\n",
            "Epoch: 13 | Iteration: 499/1000\n",
            "Loss: 1.534534003973007\n",
            "Time: 34 minute(s) 23 second(s)\n",
            "\n",
            "Epoch: 13 | Iteration: 999/1000\n",
            "Loss: 1.499918617963791\n",
            "Time: 35 minute(s) 46 second(s)\n",
            "\n",
            "Epoch: 14 | Iteration: 499/1000\n",
            "Loss: 1.5135657924413681\n",
            "Time: 37 minute(s) 9 second(s)\n",
            "\n",
            "Epoch: 14 | Iteration: 999/1000\n",
            "Loss: 1.5272996706962585\n",
            "Time: 38 minute(s) 33 second(s)\n",
            "\n",
            "Epoch: 15 | Iteration: 499/1000\n",
            "Loss: 1.520841676235199\n",
            "Time: 39 minute(s) 57 second(s)\n",
            "\n",
            "Epoch: 15 | Iteration: 999/1000\n",
            "Loss: 1.5102825253009795\n",
            "Time: 41 minute(s) 20 second(s)\n",
            "\n",
            "Epoch: 16 | Iteration: 499/1000\n",
            "Loss: 1.4952288806438445\n",
            "Time: 42 minute(s) 45 second(s)\n",
            "\n",
            "Epoch: 16 | Iteration: 999/1000\n",
            "Loss: 1.5005673627853393\n",
            "Time: 44 minute(s) 9 second(s)\n",
            "\n",
            "Epoch: 17 | Iteration: 499/1000\n",
            "Loss: 1.4805243376493453\n",
            "Time: 45 minute(s) 33 second(s)\n",
            "\n",
            "Epoch: 17 | Iteration: 999/1000\n",
            "Loss: 1.4950601580142975\n",
            "Time: 46 minute(s) 57 second(s)\n",
            "\n",
            "Epoch: 18 | Iteration: 499/1000\n",
            "Loss: 1.489663049340248\n",
            "Time: 48 minute(s) 21 second(s)\n",
            "\n",
            "Epoch: 18 | Iteration: 999/1000\n",
            "Loss: 1.4835431340932845\n",
            "Time: 49 minute(s) 44 second(s)\n",
            "\n",
            "Epoch: 19 | Iteration: 499/1000\n",
            "Loss: 1.4882734625339509\n",
            "Time: 51 minute(s) 7 second(s)\n",
            "\n",
            "Epoch: 19 | Iteration: 999/1000\n",
            "Loss: 1.4711800649166107\n",
            "Time: 52 minute(s) 30 second(s)\n",
            "\n",
            "Epoch: 20 | Iteration: 499/1000\n",
            "Loss: 1.4752202943563462\n",
            "Time: 53 minute(s) 54 second(s)\n",
            "\n",
            "Epoch: 20 | Iteration: 999/1000\n",
            "Loss: 1.4826040114164352\n",
            "Time: 55 minute(s) 18 second(s)\n",
            "\n",
            "Epoch: 21 | Iteration: 499/1000\n",
            "Loss: 1.4816911599636078\n",
            "Time: 56 minute(s) 42 second(s)\n",
            "\n",
            "Epoch: 21 | Iteration: 999/1000\n",
            "Loss: 1.470736255288124\n",
            "Time: 58 minute(s) 5 second(s)\n",
            "\n",
            "Epoch: 22 | Iteration: 499/1000\n",
            "Loss: 1.449316861987114\n",
            "Time: 59 minute(s) 29 second(s)\n",
            "\n",
            "Epoch: 22 | Iteration: 999/1000\n",
            "Loss: 1.4653571807146073\n",
            "Time: 60 minute(s) 52 second(s)\n",
            "\n",
            "Epoch: 23 | Iteration: 499/1000\n",
            "Loss: 1.4477942698001862\n",
            "Time: 62 minute(s) 15 second(s)\n",
            "\n",
            "Epoch: 23 | Iteration: 999/1000\n",
            "Loss: 1.4544460747241974\n",
            "Time: 63 minute(s) 38 second(s)\n",
            "\n",
            "Epoch: 24 | Iteration: 499/1000\n",
            "Loss: 1.4679310538768768\n",
            "Time: 65 minute(s) 0 second(s)\n",
            "\n",
            "Epoch: 24 | Iteration: 999/1000\n",
            "Loss: 1.4765984383821487\n",
            "Time: 66 minute(s) 23 second(s)\n",
            "\n",
            "Epoch: 25 | Iteration: 499/1000\n",
            "Loss: 1.4571909666061402\n",
            "Time: 67 minute(s) 46 second(s)\n",
            "\n",
            "Epoch: 25 | Iteration: 999/1000\n",
            "Loss: 1.45492179107666\n",
            "Time: 69 minute(s) 9 second(s)\n",
            "\n",
            "Epoch: 26 | Iteration: 499/1000\n",
            "Loss: 1.4460850546360016\n",
            "Time: 70 minute(s) 32 second(s)\n",
            "\n",
            "Epoch: 26 | Iteration: 999/1000\n",
            "Loss: 1.4598093514442443\n",
            "Time: 71 minute(s) 56 second(s)\n",
            "\n",
            "Epoch: 27 | Iteration: 499/1000\n",
            "Loss: 1.462186782360077\n",
            "Time: 73 minute(s) 19 second(s)\n",
            "\n",
            "Epoch: 27 | Iteration: 999/1000\n",
            "Loss: 1.4478549506664276\n",
            "Time: 74 minute(s) 43 second(s)\n",
            "\n",
            "Epoch: 28 | Iteration: 499/1000\n",
            "Loss: 1.4435850826501846\n",
            "Time: 76 minute(s) 7 second(s)\n",
            "\n",
            "Epoch: 28 | Iteration: 999/1000\n",
            "Loss: 1.4442081829309463\n",
            "Time: 77 minute(s) 31 second(s)\n",
            "\n",
            "Epoch: 29 | Iteration: 499/1000\n",
            "Loss: 1.4473021613359451\n",
            "Time: 78 minute(s) 55 second(s)\n",
            "\n",
            "Epoch: 29 | Iteration: 999/1000\n",
            "Loss: 1.4400877826213836\n",
            "Time: 80 minute(s) 19 second(s)\n",
            "\n",
            "Epoch: 30 | Iteration: 499/1000\n",
            "Loss: 1.4430786839723586\n",
            "Time: 81 minute(s) 43 second(s)\n",
            "\n",
            "Epoch: 30 | Iteration: 999/1000\n",
            "Loss: 1.4443220621347428\n",
            "Time: 83 minute(s) 6 second(s)\n",
            "\n",
            "Epoch: 31 | Iteration: 499/1000\n",
            "Loss: 1.4404934661388398\n",
            "Time: 84 minute(s) 30 second(s)\n",
            "\n",
            "Epoch: 31 | Iteration: 999/1000\n",
            "Loss: 1.4231868051290513\n",
            "Time: 85 minute(s) 54 second(s)\n",
            "\n",
            "Epoch: 32 | Iteration: 499/1000\n",
            "Loss: 1.4305523045063018\n",
            "Time: 87 minute(s) 17 second(s)\n",
            "\n",
            "Epoch: 32 | Iteration: 999/1000\n",
            "Loss: 1.4325599073171615\n",
            "Time: 88 minute(s) 40 second(s)\n",
            "\n",
            "Epoch: 33 | Iteration: 499/1000\n",
            "Loss: 1.431331359744072\n",
            "Time: 90 minute(s) 4 second(s)\n",
            "\n",
            "Epoch: 33 | Iteration: 999/1000\n",
            "Loss: 1.4466573412418366\n",
            "Time: 91 minute(s) 27 second(s)\n",
            "\n",
            "Epoch: 34 | Iteration: 499/1000\n",
            "Loss: 1.4328088686466216\n",
            "Time: 92 minute(s) 50 second(s)\n",
            "\n",
            "Epoch: 34 | Iteration: 999/1000\n",
            "Loss: 1.4373289879560471\n",
            "Time: 94 minute(s) 14 second(s)\n",
            "\n",
            "Epoch: 35 | Iteration: 499/1000\n",
            "Loss: 1.4168996574878692\n",
            "Time: 95 minute(s) 37 second(s)\n",
            "\n",
            "Epoch: 35 | Iteration: 999/1000\n",
            "Loss: 1.4169550220966338\n",
            "Time: 97 minute(s) 0 second(s)\n",
            "\n",
            "Epoch: 36 | Iteration: 499/1000\n",
            "Loss: 1.436106449842453\n",
            "Time: 98 minute(s) 23 second(s)\n",
            "\n",
            "Epoch: 36 | Iteration: 999/1000\n",
            "Loss: 1.4216231373548507\n",
            "Time: 99 minute(s) 46 second(s)\n",
            "\n",
            "Epoch: 37 | Iteration: 499/1000\n",
            "Loss: 1.4283198350667954\n",
            "Time: 101 minute(s) 9 second(s)\n",
            "\n",
            "Epoch: 37 | Iteration: 999/1000\n",
            "Loss: 1.4241182519197464\n",
            "Time: 102 minute(s) 32 second(s)\n",
            "\n",
            "Epoch: 38 | Iteration: 499/1000\n",
            "Loss: 1.4270641372203827\n",
            "Time: 103 minute(s) 54 second(s)\n",
            "\n",
            "Epoch: 38 | Iteration: 999/1000\n",
            "Loss: 1.4190276136398317\n",
            "Time: 105 minute(s) 17 second(s)\n",
            "\n",
            "Epoch: 39 | Iteration: 499/1000\n",
            "Loss: 1.4225472297668458\n",
            "Time: 106 minute(s) 39 second(s)\n",
            "\n",
            "Epoch: 39 | Iteration: 999/1000\n",
            "Loss: 1.4187509336471558\n",
            "Time: 108 minute(s) 2 second(s)\n",
            "\n",
            "Epoch: 40 | Iteration: 499/1000\n",
            "Loss: 1.4275852555036546\n",
            "Time: 109 minute(s) 25 second(s)\n",
            "\n",
            "Epoch: 40 | Iteration: 999/1000\n",
            "Loss: 1.4258439482450485\n",
            "Time: 110 minute(s) 48 second(s)\n",
            "\n",
            "Epoch: 41 | Iteration: 499/1000\n",
            "Loss: 1.4061403342485428\n",
            "Time: 112 minute(s) 11 second(s)\n",
            "\n",
            "Epoch: 41 | Iteration: 999/1000\n",
            "Loss: 1.4151564133167267\n",
            "Time: 113 minute(s) 33 second(s)\n",
            "\n",
            "Epoch: 42 | Iteration: 499/1000\n",
            "Loss: 1.4084196861982345\n",
            "Time: 114 minute(s) 56 second(s)\n",
            "\n",
            "Epoch: 42 | Iteration: 999/1000\n",
            "Loss: 1.4221934378147125\n",
            "Time: 116 minute(s) 19 second(s)\n",
            "\n",
            "Epoch: 43 | Iteration: 499/1000\n",
            "Loss: 1.421108283996582\n",
            "Time: 117 minute(s) 42 second(s)\n",
            "\n",
            "Epoch: 43 | Iteration: 999/1000\n",
            "Loss: 1.4067919981479644\n",
            "Time: 119 minute(s) 5 second(s)\n",
            "\n",
            "Epoch: 44 | Iteration: 499/1000\n",
            "Loss: 1.4009708677530288\n",
            "Time: 120 minute(s) 28 second(s)\n",
            "\n",
            "Epoch: 44 | Iteration: 999/1000\n",
            "Loss: 1.4118898465633392\n",
            "Time: 121 minute(s) 50 second(s)\n",
            "\n",
            "Epoch: 45 | Iteration: 499/1000\n",
            "Loss: 1.412353963136673\n",
            "Time: 123 minute(s) 13 second(s)\n",
            "\n",
            "Epoch: 45 | Iteration: 999/1000\n",
            "Loss: 1.403482313632965\n",
            "Time: 124 minute(s) 36 second(s)\n",
            "\n",
            "Epoch: 46 | Iteration: 499/1000\n",
            "Loss: 1.4121248451471329\n",
            "Time: 125 minute(s) 59 second(s)\n",
            "\n",
            "Epoch: 46 | Iteration: 999/1000\n",
            "Loss: 1.4062955178022385\n",
            "Time: 127 minute(s) 22 second(s)\n",
            "\n",
            "Epoch: 47 | Iteration: 499/1000\n",
            "Loss: 1.412671119093895\n",
            "Time: 128 minute(s) 44 second(s)\n",
            "\n",
            "Epoch: 47 | Iteration: 999/1000\n",
            "Loss: 1.4092669942378997\n",
            "Time: 130 minute(s) 8 second(s)\n",
            "\n",
            "Epoch: 48 | Iteration: 499/1000\n",
            "Loss: 1.3948624843358994\n",
            "Time: 131 minute(s) 30 second(s)\n",
            "\n",
            "Epoch: 48 | Iteration: 999/1000\n",
            "Loss: 1.3986637486219407\n",
            "Time: 132 minute(s) 52 second(s)\n",
            "\n",
            "Epoch: 49 | Iteration: 499/1000\n",
            "Loss: 1.3961187099218368\n",
            "Time: 134 minute(s) 15 second(s)\n",
            "\n",
            "Epoch: 49 | Iteration: 999/1000\n",
            "Loss: 1.3885600484609604\n",
            "Time: 135 minute(s) 37 second(s)\n",
            "\n",
            "Epoch: 50 | Iteration: 499/1000\n",
            "Loss: 1.3879073868989944\n",
            "Time: 136 minute(s) 59 second(s)\n",
            "\n",
            "Epoch: 50 | Iteration: 999/1000\n",
            "Loss: 1.3917457951307297\n",
            "Time: 138 minute(s) 20 second(s)\n",
            "\n",
            "Epoch: 51 | Iteration: 499/1000\n",
            "Loss: 1.3948890964984895\n",
            "Time: 139 minute(s) 42 second(s)\n",
            "\n",
            "Epoch: 51 | Iteration: 999/1000\n",
            "Loss: 1.4072315464019776\n",
            "Time: 141 minute(s) 5 second(s)\n",
            "\n",
            "Epoch: 52 | Iteration: 499/1000\n",
            "Loss: 1.4095540151596069\n",
            "Time: 142 minute(s) 28 second(s)\n",
            "\n",
            "Epoch: 52 | Iteration: 999/1000\n",
            "Loss: 1.393188442826271\n",
            "Time: 143 minute(s) 52 second(s)\n",
            "\n",
            "Epoch: 53 | Iteration: 499/1000\n",
            "Loss: 1.4113989065885544\n",
            "Time: 145 minute(s) 16 second(s)\n",
            "\n",
            "Epoch: 53 | Iteration: 999/1000\n",
            "Loss: 1.3971474059820175\n",
            "Time: 146 minute(s) 40 second(s)\n",
            "\n",
            "Epoch: 54 | Iteration: 499/1000\n",
            "Loss: 1.3971094464063645\n",
            "Time: 148 minute(s) 4 second(s)\n",
            "\n",
            "Epoch: 54 | Iteration: 999/1000\n",
            "Loss: 1.392347540974617\n",
            "Time: 149 minute(s) 28 second(s)\n",
            "\n",
            "Epoch: 55 | Iteration: 499/1000\n",
            "Loss: 1.4127866327762604\n",
            "Time: 150 minute(s) 52 second(s)\n",
            "\n",
            "Epoch: 55 | Iteration: 999/1000\n",
            "Loss: 1.398018509864807\n",
            "Time: 152 minute(s) 16 second(s)\n",
            "\n",
            "Epoch: 56 | Iteration: 499/1000\n",
            "Loss: 1.4039191815853118\n",
            "Time: 153 minute(s) 40 second(s)\n",
            "\n",
            "Epoch: 56 | Iteration: 999/1000\n",
            "Loss: 1.3808926519155502\n",
            "Time: 155 minute(s) 4 second(s)\n",
            "\n",
            "Epoch: 57 | Iteration: 499/1000\n",
            "Loss: 1.3890264467000961\n",
            "Time: 156 minute(s) 28 second(s)\n",
            "\n",
            "Epoch: 57 | Iteration: 999/1000\n",
            "Loss: 1.3935301005840302\n",
            "Time: 157 minute(s) 53 second(s)\n",
            "\n",
            "Epoch: 58 | Iteration: 499/1000\n",
            "Loss: 1.381890775680542\n",
            "Time: 159 minute(s) 17 second(s)\n",
            "\n",
            "Epoch: 58 | Iteration: 999/1000\n",
            "Loss: 1.3772259010076522\n",
            "Time: 160 minute(s) 40 second(s)\n",
            "\n",
            "Epoch: 59 | Iteration: 499/1000\n",
            "Loss: 1.3949603731632232\n",
            "Time: 162 minute(s) 5 second(s)\n",
            "\n",
            "Epoch: 59 | Iteration: 999/1000\n",
            "Loss: 1.3893786195516586\n",
            "Time: 163 minute(s) 29 second(s)\n",
            "\n",
            "Epoch: 60 | Iteration: 499/1000\n",
            "Loss: 1.3796558109521866\n",
            "Time: 164 minute(s) 53 second(s)\n",
            "\n",
            "Epoch: 60 | Iteration: 999/1000\n",
            "Loss: 1.3720582461357116\n",
            "Time: 166 minute(s) 17 second(s)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e3WAFydQ08rN"
      },
      "source": [
        "### Training Loss Curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-15T00:38:13.728474Z",
          "start_time": "2019-05-15T00:38:13.559531Z"
        },
        "colab_type": "code",
        "id": "iS_jl7TJ08rO",
        "outputId": "21f56573-55cb-463a-b68f-5de32a37316c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.plot(model.loss_history, label = 'LSTM')\n",
        "plt.plot()\n",
        "plt.legend(loc = \"best\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C7840wu608rR"
      },
      "source": [
        "### Sample of Generated Sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-15T03:10:52.267837Z",
          "start_time": "2019-05-15T03:10:51.986701Z"
        },
        "colab_type": "code",
        "id": "-EsdRUs308rS",
        "scrolled": true,
        "outputId": "894559cf-e20d-49b3-ac65-a8d1bb540d95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print('LSTM Sample Generation:\\n\\n')\n",
        "print(model.generate(predicted_length = 5000))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTM Sample Generation:\n",
            "\n",
            "\n",
            "What, I did wold, my good s event\n",
            "Our kings\n",
            "\n",
            "QUEEN ELIZABETH\n",
            "But good moul we beg.\n",
            "\n",
            "ISABELLA\n",
            "Yes, in but we know what boy\n",
            "My tenrery cast hackblate of mistress\n",
            "\n",
            "DUKE OF YORK\n",
            "Heth his word more.\n",
            "\n",
            "MARIANA\n",
            "Gensle what if Fir you mine pleasure, and then spiriting.\n",
            "\n",
            "SLY\n",
            "\n",
            "First\n",
            "Great as thy gracious lament\n",
            "Mnex. \n",
            "NORTHAPARO\n",
            "Contation Hast undenheli, pray yourcelCAY\n",
            "Where we tell outfully doth he I do undue Kate Confest.\n",
            "So for the world to me, have my fort;\n",
            "And he will jass. Most I have we live\n",
            "The I same me at the errazenest forgeds forbas.\n",
            "Should hast it pity worthy that singer mex should gla,\n",
            "And, your horse on justice I'll comhound\n",
            "In with forged adman,\n",
            "Is not you discomf he\n",
            "His one sole tham giveft.\n",
            "\n",
            "MARCIUS\n",
            "O swoman.\n",
            "I.\n",
            "Whom thou calmpnat be so legler, they became my needs\n",
            "Ours\n",
            "\n",
            "JULIET\n",
            "Doth these marry, you innocence forstand\n",
            "Commend me now, men by the lengm unwiltewn trumbet nihestly saln.\n",
            "\n",
            "MAMIICHER,\n",
            "That thet, I know, by thy mifficey, wears\n",
            "So my son, hither Angelo. I hates\n",
            "Or gravoise with quarrelle mightwoul\n",
            "by thy daughter, look that the equant\n",
            "Beget, the agreety his sacrifice motald,\n",
            "Ro that strictly sounded out this compender brish\n",
            "her\n",
            "And wome your life resolved.\n",
            "\n",
            "AUFIDIUS\n",
            "Did murder again\n",
            "Tell Menesture, this hunting peace, my lifs as either.\n",
            "Fie, that the world was won you farthed aDm;\n",
            "Your action silg greet of boghe,\n",
            "Then we desire to moust villain\n",
            "\n",
            "DUKE VINCENTIO\n",
            "My Auwilt.\n",
            "\n",
            "PROSPERO\n",
            "Not he say\n",
            "\n",
            "CORIOLANUS\n",
            "NailThour in England's untear\n",
            "There, weeking Cominius can sield it.\n",
            "\n",
            "POLIXENEI\n",
            "Is worthier pearding.\n",
            "\n",
            "MENENIUS\n",
            "Their anking,\n",
            "Thon my princess, O thou desertd'st not quarred.\n",
            "My\n",
            "back of the ceorce inditerisous,, and by my saken.\n",
            "\n",
            "BENVOLIO\n",
            "Inconspane, she, deliver hid with your warlection,\n",
            "Chrissevice have got, to-morrow a fuil; and let\n",
            "him to my worghous broneghe whoseak\n",
            "\n",
            "CORIOLANUS\n",
            "Tullus,\n",
            "Of mine inds it and wish, as I say,\n",
            "Hwer lessen by a lord to fall but see,\n",
            "And wemilies he a\n",
            "clothe a boat.\n",
            "\n",
            "First Citizen\n",
            "Believes, gazet, wilt you not I stand in't of that\n",
            "keep-logged to kill'd thee by the voscaugh,\n",
            "I have revenged acdolve's commider'\n",
            "soothant Pign with love Vous\n",
            "Awaking cleign-sail to him repowe you.\n",
            "\n",
            "Nurse\n",
            "We have levies, a't, and you at all K\n",
            "The eyes yarrd than worky more than MOPSO\n",
            "Kood morning; and my son herein\n",
            "And tallotten their and Grepainer\n",
            "Unto with these cortiness driel, though you\n",
            "Whither ade me for this queens; and you came, arisor\n",
            "For hold the witls, If we be; the dreshans at,\n",
            "Yes, good most gruns.\n",
            "\n",
            "All\n",
            "Thou wilt\n",
            "We warriff hears it, go their ebeen, that 'tisforts and so\n",
            "The most manvilins 'gainst judgment from the match\n",
            "What, and how like Yan O mnrewegest,\n",
            "To husband are, by the mother often Hereford.\n",
            "When, death, forget in mine. Fatherrece\n",
            "Than he pressest my ancient bonss.\n",
            "Take gone. Caglanita.\n",
            "\n",
            "FRIAR LAURENCE\n",
            "This court.\n",
            "\n",
            "COMINIUS\n",
            "Is, and ality way\n",
            "\n",
            "GLOUCESTER\n",
            "Good senutor and here\n",
            "\n",
            "First Citizen\n",
            "Become this whip thee stand\n",
            "And comfort, both one anourging, no word.\n",
            "\n",
            "QUEEN MALGARET\n",
            "Obey, daily maliwing ornly in becomes\n",
            "Which alterforcoct by the leating.\n",
            "\n",
            "PETRUCHIO\n",
            "Harr's, hasty wrecks of fight, vizend the plantasor\n",
            "it shallinglds well by the father smeak needs her enactings,\n",
            "Which at this yard cait for and foe yet,\n",
            "Where for so Warwick's hand is these yet That said\n",
            "How to I revelp the nurse, if lores\n",
            "And on the time tevize himself in the inigh,\n",
            "Inductuo of this drain I say, the smires hath auched\n",
            "erefores of him hermoow.\n",
            "A in,\n",
            "'hortermy keiping.\n",
            "\n",
            "CAMILLO\n",
            "Alsh, not good life, that which I uncarted alace\n",
            "He crive and not cordned friar\n",
            "\n",
            "Nurse\n",
            "Is still bodied\n",
            "Sweet Trows, promise in theeas reporsing old sense.\n",
            "\n",
            "BRIKE\n",
            "Good new age; and no hard this,\n",
            "You did not o'er, to me, like sucks, the condetting,\n",
            "This idle such the tiejest ennowing wench;\n",
            "And, have stucks, woe too ashamp forteney Cotizan\n",
            "Think not him to, kincher;\n",
            "Of me seeing your chat being the leather sea-\n",
            "What sieges noot the crueldce tally, your state\n",
            "When me, ten inhalk, let us porting,\n",
            "Corn that did a rdpen in your majesty\n",
            "That scatter no mforge, and a browd toir,\n",
            "Heture; by  he has the bul, he slrow's\n",
            "Hath you fear, and all thus 'Clarence-\n",
            "\n",
            "GREGORAPESS\n",
            "Ill, your blaXENES The prince's. And hares me meland in cor it my rayor. sudden\n",
            "\n",
            "LUCENTIO\n",
            "My lord.\n",
            "\n",
            "Herom. Heavenmelled it speak,\n",
            "Conformitena, but his heart knows that,\n",
            "And I commind the praity betters\n",
            "did guess of brat of good fetch with thy grief\n",
            "If thou hrencaws ttut F, and your dististaks,\n",
            "Permitation and news.\n",
            "I prithee, and sir, he did go't on you.\n",
            "\n",
            "KING EDWARD IV\n",
            "IZAlet heart thy every soroth,\n",
            "and so lie no.\n",
            "\n",
            "Auntatians\n",
            "O I look thus give it down for\n",
            "itter\n",
            "Into your grace but I prays it beygave;\n",
            "She's not can fendical, cure to night\n",
            "Spare Seating bound the king comes me, feigns,\n",
            "To fatred in thy life they was--tht to know your highess,\n",
            "Born most damned two being a right,\n",
            "With curchs are to recell in writes,\n",
            "And make thee a knows to strange in hand,\n",
            "Noger not quench agier lie for; first,\n",
            "To place 'tis a herd. Whace mude,\n",
            "Against the breath and is to thAs inc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8nwJ8b6pLdwI"
      },
      "source": [
        "### Loss distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F7Z7jNOQKSSv",
        "outputId": "a58ea25b-8dc2-44b2-b4fb-e6d79ba4bdf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "mean_lstm_loss = np.mean(model.loss_history)\n",
        "print('Average loss for LSTM network:\\n', mean_lstm_loss)\n",
        "\n",
        "final_lstm_loss = model.loss_history[-1]\n",
        "print('\\nFinal loss for LSTM network:\\n', final_lstm_loss)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average loss for LSTM network:\n",
            " 1.4886059596776962\n",
            "\n",
            "Final loss for LSTM network:\n",
            " 1.3720582461357116\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}